---
title: "MATH501 Modelling and Analytics for Data Science Coursework"
author: "Maravegias"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output: 
  pdf_document:
    number_sections: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load libraries, include=FALSE, message = FALSE}
library(tidytext)
library(tidyr)
library(readr)
library(dplyr)
library(ggplot2)
library(scales)
library(grid)
library(lemon)
```

```{r functions to be used, include=FALSE}
plot_gghistogram <- function(data = df_tele, 
                             x, 
                             x_lab = '',
                             hue = churn, 
                             fill_color_1 = 'black', 
                             fill_color_2 = 'black',
                             color_color_1 = 'tomato',
                             color_color_2 = 'steelblue') {
  data %>%
    ggplot()+
    geom_histogram(aes(x = x, fill = hue), alpha=0.5)+
    labs(x = x_lab,
        y = "Count",
        fill = "Did user left?")+
    theme(axis.text = element_text(size = 13, color = "black"),
        axis.title = element_text(size = 13, color = "black")) +
    scale_color_manual(values = c("yes" = fill_color_1, 
                                "no" = fill_color_2)) +
    scale_fill_manual(values = c("yes" = color_color_1, 
                                "no" = color_color_2))
}

plot_boxplot <- function(data = df_tele, 
                         y, 
                         hue = churn,
                         x_lab = '',
                         y_lab = '',
                         fill_color_1 = 'black', 
                         fill_color_2 = 'black',
                         color_color_1 = 'tomato',
                         color_color_2 = 'steelblue') {
  data %>%
    ggplot(aes(hue, y, fill=hue))+
    geom_boxplot(varwidth = TRUE)+
    labs(x=x_lab,
         y=y_lab,
    fill = "Did user left?")+
    theme(axis.text = element_text(size = 13, color = "black"),
        axis.title = element_text(size = 13, color = "black")) +
    scale_color_manual(values = c("yes" = fill_color_1, 
                                "no" = fill_color_2)) +
    scale_fill_manual(values = c("yes" = color_color_1, 
                                "no" = color_color_2))+
  stat_summary(fun = mean,
               colour="darkblue",
               geom = "point",
               shape = 18,
               size = 3,
               show.legend = FALSE) +
  stat_summary(fun = mean,
               colour = "darkblue",
               geom = "text",
               show.legend = FALSE,
               vjust = -0.7,
               aes(label = round(..y.., digits = 2))) +
  theme(legend.position = "bottom")
}

plot_scatter <- function(data = df_tele, 
                         x,
                         y,
                         x_lab = '',
                         y_lab = '',
                         hue = churn, 
                         color_1 = 'tomato', 
                         color_2 = 'steelblue'){
 
  data %>%
    ggplot()+
    geom_point(aes(x = x, y = y, color = hue))+
    labs(x = x_lab,
         y = y_lab,
         color = "Did user left?")+
    theme(axis.text = element_text(size = 13, color = "black"),
          axis.title = element_text(size = 13, color = "black"))+
    scale_color_manual(values = c("yes" = color_1, 
                            "no" = color_2))
}

get_legend<-function(myggplot){
  tmp <- ggplot_gtable(ggplot_build(myggplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}
  
# https://stackoverflow.com/questions/12539348/ggplot-separate-legend-and-plot
```
# Machine Learning Task

## Data exploration

```{r load file, message=FALSE, include=FALSE}
setwd("C:/Users/kwsta/master_projects/math501")
df_tele <- read.table("churndata.txt")
df_tele$churn <- as.factor(df_tele$churn) # converting churn to a factor variables
attach(df_tele)
```
The data set has information about 500 costumers of a telecom company. It consists 
of 500 rows and 5 columns.

```{r show_df_head, echo=FALSE}
head(df_tele)
dim(df_tele)
```
### Summary Statistics

```{r summary_stats, echo=FALSE, warning=FALSE, message=FALSE}
df_tele %>%
  group_by(churn) %>%
  summarise(mean_upload = mean(upload),
            mean_webget = mean(webget),
            mean_callwait = mean(callwait))

summary(df_tele)
```
From the tables above we can notice that there is a difference in the means of the
customers who switched to another telecommunication provider.

Furthermore it is important to say, that we have an unbalanced data set, since 
that the customers who switched provider are way less (`r 103/500*100`% )than those who do not.
An unbalanced data set can affect our model performance. Models train on unbalanced datasets usually suffer from poor accuracy when have to generalize, since the algorithm will be more biased towards the majority class. 

## Machine Learning Part (a)

```{r initializing_the_plots, echo=FALSE}

upload_hist <- plot_gghistogram(x=upload, x_lab='Upload speed')
webget_hist <- plot_gghistogram(x=webget, x_lab='Mean time to load a webpage')
enqcount_hist <- plot_gghistogram(x=enqcount, x_lab='Enquiry count')
callwait_hist <- plot_gghistogram(x=callwait, x_lab='Waited time')

upload_box <- plot_boxplot(y=upload, y_lab = 'Upload speed')
webget_box <- plot_boxplot(y=webget, y_lab='Mean time to load a webpage')
enqcount_box <- plot_boxplot(y=enqcount, y_lab='Enquiry count')
callwait_box <- plot_boxplot(y=callwait, y_lab='Waited time')

upload_webget_scatter <- plot_scatter(x = upload, y = webget, x_lab = 'Upload speed', y_lab = 'mean load time')
upload_callwait_scatter <- plot_scatter(x = upload, y = callwait,  x_lab = 'Upload speed', y_lab = 'Wait time')
webget_callwait_scatter <- plot_scatter(x = webget, y = callwait, x_lab = 'Mean load time', y_lab = 'Wait time')
enqcount_callwait_scatter <- plot_scatter(x = enqcount, y= callwait, x_lab = 'Enquiry count', y_lab='Wait time')
enqcount_webget_scatter <- plot_scatter(x = enqcount, y= webget, x_lab = 'Enquiry count', y_lab='Mean time to load a webpage')

```

```{r ploting, echo=FALSE, message=FALSE }

grid_arrange_shared_legend(upload_hist, webget_hist, enqcount_hist, callwait_hist, nrow = 2, ncol = 2)
grid_arrange_shared_legend(upload_box, webget_box, enqcount_box, callwait_box, nrow = 2, ncol = 2)
grid_arrange_shared_legend(upload_webget_scatter, upload_callwait_scatter, webget_callwait_scatter, enqcount_callwait_scatter,nrow = 2, ncol = 2)
enqcount_webget_scatter
# https://stackoverflow.com/questions/1249548/side-by-side-plots-with-ggplot2
detach(df_tele)
```
While observing the histogramms we can conclude the following:

1. The majority of the customers, have not switched to another provider. 
2. The proportion of customers who have switched, tend to have higher upload speed.
3. The mean time to load a webpage, for he majority of the customers who remained 
loyal the company, is between 200 - 400. If the value increases, the chance for 
a customer to switch provider increases.
4. The customers who have called the company 7 times tend to switch provider.
5. The distribution of waiting time for the both classes is similar.

From the boxplots we notice the below:

1. The boxplot of uploading speed for those who have not switched, is relatively narrow,
indicating that overall there is not a high degree of variation of their upload speeds. 
In contrasts those who have switched provider, have a higher variance of upload speed. 
Furthermore it is clear that those who have switched tend to have higher upload speeds, 
while their max observed value is about 3 points greater from the max speed of the other group.

2. We notice that the boxplot indicating the mean time to load a webpage is too 
narrow (whiskers include), for the group who stayed in the company, indicating a very small variance. In more details the 75%
of this group witness mean time about 180-400. Their appear to be a few outlines at the value 1000. 
On the other hand we notice, that the loading time varies more for those who switched providers, since 50% of them experience
loading time from about 380 to 700. We can clearly state that the group who switched provider have greater waiting times.

3. Those who have not switched provider, have contracted less times the company in average (3.13), compare to those who do not (4.36).
This can be explained, because customers facing connection issues tend to call more, and if their issues are not being solved they tend to switch providers. Also we notice that the max times someone have called the company is 7 times. Furthermore the boxplot fo the group who switched
provider have no upper whisker, since the limit of the IQR is the same of the upper limit of the values. 
This can be explained by the extreme skewness of the data (the majority are 7).

5. There appears not to be any great difference of the waiting time between the two groups, while the median seems the same (8). The IQR of those who switched the company, is little wider, due to the longer upper whisker. The max value for those who switched is about 15, while for the other group 12.5. Both groups show some outlines for the value of 0, indicating that many customers did not waited (maybe because they never called)
to be attended by a customer service operator.



## Machine Learning Part (b)

```{r train_test_split, echo=FALSE}
set.seed(1)
df_subset <- sample(500, 350)

df_train_tele <- df_tele[df_subset,]
df_test_tele <- df_tele[-df_subset,]

head(df_train_tele)
head(df_test_tele)
```

## Machine Learning Part (c)

KNN classifier makes predictions based on the Euclidean distance, thus the scale
of the variables matter. If we do not scale the data, variables with high variance (wider range),
will effect more the Euclidean distance and will appear to be more important for
the determination the target value.
Since we do not know the scales of our variables, its wise to scale our data.
However, since our variables always get positive numbers as values, we used the 
max-min normalization. We have to keep in mind normalization does not
handle the outlines well.

$$
x' =\frac{x - min(x)}{max(x)-min(x)}
$$
Where:
 - $x'$: the normalized value
 - $x$: the original value


```{r min_max_normalizer, include=FALSE}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}

df_train_tele_norm <- normalize(df_train_tele[,-5])
df_train_tele_norm$churn <- df_train_tele$churn

df_test_tele_norm <- normalize(df_test_tele[,-5])
df_test_tele_norm$churn <- df_test_tele$churn

```


```{r cross_validation, include=FALSE}
library(class)
set.seed(1)
cross_knn_error <- c()
error <- c()
for(i in 1:100){
  cross_knn <- knn.cv(df_train_tele_norm[,-5], 
                      df_train_tele_norm[,5], 
                      k = i, 
                      l = 0, 
                      prob = FALSE, 
                      use.all = TRUE)
  cross_knn_error[i] <- mean(cross_knn != df_train_tele_norm[,5])
}
```

```{r plot_errors, echo=FALSE}
plot(cross_knn_error[1:30], xlab = 'k', ylab = 'Error', col = 'blue')
```
According to the graph, for k=1 or k=7 we have the same error,
however it is important to check the confusion matrix.

```{r knn_with_best_k, echo=FALSE}
library(caret)
set.seed(1)
normalized_knn <- knn(train = df_train_tele_norm[,-5], 
                      test = df_test_tele_norm[,-5], 
                      cl=df_train_tele_norm$churn, 
                      k=1)


norm_knn_accuracy <- mean(normalized_knn == df_test_tele_norm$churn)
norm_knn_accuracy

best_knn <- knn(train = df_train_tele_norm[,-5], 
                test = df_test_tele_norm[,-5], 
                cl=df_train_tele_norm$churn, 
                k=7)

best_acc <- mean(best_knn == df_test_tele_norm$churn)
best_acc
table(normalized_knn, df_test_tele_norm$churn)
table(best_knn, df_test_tele_norm$churn)
confusionMatrix(normalized_knn, df_test_tele_norm$churn)
```
We notice that for the both values of k, the algorithm struggles to predict
correct the values of yes, while the majority of the values are assigned as no.
That is an issue resulted from the imbalance of our set.

We prefer the value for k=1, since predicts better those who switched provider.

## Machine Learning part (d)
```{r machine_learning_part_d, echo=FALSE}
library(randomForest)
set.seed(1)
bag_tree_train <-randomForest(formula =  df_train_tele[,5] ~., 
                              data=df_train_tele[,-5], 
                              mtry=4, 
                              importance=TRUE,
                              ntree=500)
varImpPlot(bag_tree_train)
importance(bag_tree_train) 
```

Mean decrease Accuracy reflects how much accuracy is lost by excluding its variable,
thus the more the accuracy decrease the more important this variable is. 

Mean decrease Gini, shows the total decrease in node impurity resulted by the splits
of a given variable, averaged over all trees. If a variable is useful. it tends to split a node into pure single class nodes. Thus, removing such variable, results a decrease in the average gain of the purity resulted by this variable. 

We notice that webget and enqcount results the most mean decrease accuracy and gini.
Also, upload scores higher in the mean decrease accuracy than callwait, while callwait scores better in gini, but with smaller spread.  

In overall, we could argue that webget and enqcount are the most significant variables for classifying if a customer will switch provider. 

```{r random_forest_acc, echo=FALSE}
bag_tree_pred <- predict(bag_tree_train, newdata = df_test_tele)
bag_tree_train_acc <- mean(bag_tree_pred == df_test_tele[,5])
bag_tree_train_acc
table(bag_tree_pred, df_test_tele[,5])
```

We notice that the random forest performs better compared to the KNN algorithm.
The better accuracy stems from the fact that scored better on the True Positives.
The KNN scored very poorly, on predicting those who switched provider predicting (only 3 out of the 34). 
This stems from the unbalanced of our data set. 

## Machine Learning Part (e)
```{r part_e_PCA, echo=FALSE}

df_tele_norm <- normalize(df_tele[,-5])
df_tele_norm$churn <- df_tele$churn

tele_pca <- princomp(df_tele_norm[,-5], cor = TRUE)
summary(tele_pca)
plot(tele_pca)
```

```{r ploting_comp1_v_comp2, echo=FALSE}
new_variables <- tele_pca$scores[,1:2]
new_variables <- data.frame(new_variables)
new_variables$churn <- as.factor(df_tele_norm$churn)
p<-new_variables %>%
  ggplot()+
  geom_point(aes(x=Comp.1, y = Comp.2, color=churn)) +
  labs(x = "First Principal Component",
       y = "Second Principal Component") +
  coord_fixed(ratio = 1)
p

plot(new_variables$Comp.1, new_variables$Comp.2)
```
The information preserved in this plot equals to the proportion of the variances 
of the two components so is 73.5%


## Machine Learning Part (f)
```{r random_forest_with_comp1_comp2, echo=FALSE}
# splitting the data
comp_df_train <- new_variables[df_subset,]
comp_df_test <- new_variables[-df_subset,]

comp_forest <-randomForest(formula = churn ~., 
                           data=comp_df_train, 
                           mtry=2, 
                           importance=TRUE)

varImpPlot(comp_forest)
importance(comp_forest) 
```

```{r model_acc, echo=FALSE}
comp_forest_pred <- predict(comp_forest, newdata = comp_df_test[,-3])
comp_forest_acc <- mean(comp_forest_pred == comp_df_test[,3])
comp_forest_acc
table(comp_forest_pred, comp_df_test[,3])
```

```{r visulization_of_classification, echo=FALSE}
comp_df_test$predictions <-comp_forest_pred

comp_df_test%>%
ggplot()+
  geom_point(aes(x=Comp.1, y = Comp.2, color=predictions)) +
  labs(x = "First Principal Component",
       y = "Second Principal Component",
       title = 'Predictions') +
  coord_fixed(ratio = 1)

comp_df_test%>%
ggplot()+
  geom_point(aes(x=Comp.1, y = Comp.2, color=churn)) +
  labs(x = "First Principal Component",
       y = "Second Principal Component",
       title = 'Actual') +
  coord_fixed(ratio = 1)
```


```{r}
len <- 12 
xp <- seq(-2.5, 6, length = len) 
yp <- seq(-2.5, 4, length = len) 
xygrid <- expand.grid(Comp.1 = xp, Comp.2 = yp)

col3 <- rep("lightgreen", len*len) 

for(i in 1:(len*len)){
   if(comp_forest_pred[i]== 'Yes'){ 
     col3[i] <- "blue" 
   } else {
     col3[i] <- "red"
   }
}


plot(xygrid, col = col3, main = "Tree", xlab = "pressure", ylab = "wind") 

# abline( h = c(62.5, 32.5))
# lines( x = c(985.5, 985.5), y = c(32.5, 62.5))
# 
# points(pressure, wind, col = cols, pch = 16)

```