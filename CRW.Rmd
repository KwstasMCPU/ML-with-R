---
title: "MATH501 Modelling and Analytics for Data Science Coursework"
author: "Maravegias"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output: 
  pdf_document:
    number_sections: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Machine Learning Task

```{r load libraries, echo=FALSE, include=FALSE}
library(tidytext)
library(tidyr)
library(readr)
library(dplyr)
library(ggplot2)
library(scales)
library(grid)
```

```{r functions to be used, echo=FALSE, include=FALSE}
plot_gghistogram <- function(data = df_tele, 
                             x, 
                             x_lab = '',
                             hue = churn, 
                             fill_color_1 = 'black', 
                             fill_color_2 = 'black',
                             color_color_1 = 'tomato',
                             color_color_2 = 'steelblue') {
  data %>%
    ggplot()+
    geom_histogram(aes(x = x, fill = hue), alpha=0.5)+
    labs(x = x_lab,
        y = "Count",
        fill = "Did user left?")+
    theme(axis.text = element_text(size = 13, color = "black"),
        axis.title = element_text(size = 13, color = "black")) +
    scale_color_manual(values = c("yes" = fill_color_1, 
                                "no" = fill_color_2)) +
    scale_fill_manual(values = c("yes" = color_color_1, 
                                "no" = color_color_2))
}

plot_boxplot <- function(data = df_tele, 
                         y, 
                         hue = churn,
                         x_lab = '',
                         y_lab = '',
                         fill_color_1 = 'black', 
                         fill_color_2 = 'black',
                         color_color_1 = 'tomato',
                         color_color_2 = 'steelblue') {
  data %>%
    ggplot(aes(hue, y, fill=hue))+
    geom_boxplot(varwidth = TRUE)+
    labs(x=x_lab,
         y=y_lab,
    fill = "Did user left?")+
    theme(axis.text = element_text(size = 13, color = "black"),
        axis.title = element_text(size = 13, color = "black")) +
    scale_color_manual(values = c("yes" = fill_color_1, 
                                "no" = fill_color_2)) +
    scale_fill_manual(values = c("yes" = color_color_1, 
                                "no" = color_color_2))+
  stat_summary(fun = mean,
               colour="darkblue",
               geom = "point",
               shape = 18,
               size = 3,
               show.legend = FALSE) +
  stat_summary(fun = mean,
               colour = "darkblue",
               geom = "text",
               show.legend = FALSE,
               vjust = -0.7,
               aes(label = round(..y.., digits = 2))) +
  theme(legend.position = "bottom")
}


plot_scatter <- function(data = df_tele, 
                         x,
                         y,
                         x_lab = '',
                         y_lab = '',
                         hue = churn, 
                         color_1 = 'tomato', 
                         color_2 = 'steelblue'){
 
  data %>%
    ggplot()+
    geom_point(aes(x = x, y = y, color = hue))+
    labs(x = x_lab,
         y = y_lab,
         color = "Did user left?")+
    theme(axis.text = element_text(size = 13, color = "black"),
          axis.title = element_text(size = 13, color = "black"))+
    scale_color_manual(values = c("yes" = color_1, 
                            "no" = color_2))
}



# ggplot(wages_df, aes(x = union_status, y = wage, 
#                      colour = union_status)) +
#   geom_boxplot(varwidth = TRUE) +
#   geom_jitter(width = 0.05) +
#   labs(x = "Union Status",
#        y = "Wage (Euros)") +
#   stat_summary(fun = mean, 
#                colour="darkblue", 
#                geom = "point", 
#                shape = 18, 
#                size = 3,
#                show.legend = FALSE) +
#   stat_summary(fun = mean, 
#                colour = "darkblue", 
#                geom = "text", 
#                show.legend = FALSE, 
#                vjust = -0.7, 
#                aes(label = round(..y.., digits = 2))) +
#   theme(legend.position = "bottom")


get_legend<-function(myggplot){
  tmp <- ggplot_gtable(ggplot_build(myggplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}
  
# https://stackoverflow.com/questions/12539348/ggplot-separate-legend-and-plot
```

## Data exploration

```{r load file, message=FALSE, echo = FALSE, include=FALSE}
setwd("C:/Users/kwsta/master_projects/math501")
df_tele <- read.table("churndata.txt")
df_tele$churn <- as.factor(df_tele$churn) # factor from the beginning 
attach(df_tele)
```

```{r}
df_tele
```
### Summary Statistics

```{r summary_stats, echo=FALSE}
df_tele %>%
  group_by(churn) %>%
  summarise(mean_upload = mean(upload),
            mean_webget = mean(webget),
            mean_callwait = mean(callwait))

summary(df_tele)
```

### Data visuals
## Machine Learning Part (a)

```{r, boxplots, echo=FALSE}
par(mfrow = c(1,2)) # divide the graphics window into 2 columns
boxplot(upload ~ churn, xlab = "Default", ylab = "Upload",
col = c("lightblue", "orange"))
boxplot(webget ~ churn, xlab = "Default", ylab = "Webget",
col = c("lightblue", "orange"))
par(mfrow = c(1,2))
boxplot(enqcount ~ churn, xlab = "Default", ylab = "enqcount",
col = c("lightblue", "orange"))
boxplot(callwait ~ churn, xlab = "Default", ylab = "callwait",
col = c("lightblue", "orange"))

```

```{r, histogram, echo=FALSE}

upload_hist <- plot_gghistogram(x=upload, x_lab='Upload speed')
webget_hist <- plot_gghistogram(x=webget, x_lab='Mean time to load a webpage')
enqcount_hist <- plot_gghistogram(x=enqcount, x_lab='Enquiry count')
callwait_hist <- plot_gghistogram(x=callwait, x_lab='Waited time')

#ggplot(df_tele, aes(factor(enqcount, levels = c(0:7)), upload, fill= churn))+
# geom_boxplot()

upload_box <- plot_boxplot(y=upload, y_lab = 'Upload speed')
webget_box <- plot_boxplot(y=webget, y_lab='Mean time to load a webpage')
enqcount_box <- plot_boxplot(y=enqcount, y_lab='Enquiry count')
callwait_box <- plot_boxplot(y=callwait, y_lab='Waited time')

upload_webget_scatter <- plot_scatter(x = upload, y = webget, x_lab = 'Upload speed', y_lab = 'mean load time')
upload_callwait_scatter <- plot_scatter(x = upload, y = callwait,  x_lab = 'Upload speed', y_lab = 'Wait time')
webget_callwait_scatter <- plot_scatter(x = webget, y = callwait, x_lab = 'Mean load time', y_lab = 'Wait time')
enqcount_callwait_scatter <- plot_scatter(x = enqcount, y= callwait, x_lab = 'Enquiry count', y_lab='Wait time')
enqcount_webget_scatter <- plot_scatter(x = enqcount, y= webget, x_lab = 'Enquiry count', y_lab='Mean time to load a webpage')

```

```{r}
library(lemon)

# https://stackoverflow.com/questions/1249548/side-by-side-plots-with-ggplot2
grid_arrange_shared_legend(upload_hist, webget_hist, enqcount_hist, callwait_hist, nrow = 2, ncol = 2)
grid_arrange_shared_legend(upload_box, webget_box, enqcount_box, callwait_box, nrow = 2, ncol = 2)
upload_webget_scatter
upload_callwait_scatter
webget_callwait_scatter
enqcount_callwait_scatter
enqcount_webget_scatter
```

### Machine Learning Part (b)

```{r}
set.seed(1)
df_subset <- sample(500, 350)

x_train_tele <- df_tele[df_subset,-5]
y_train_tele <- df_tele[df_subset, 5]

x_test_tele <- df_tele[-df_subset,-5]
y_test_tele <- df_tele[-df_subset, 5]
```

### Machine Learning Part (c)

KNN classifier makes predictions based on the Euclidean distance, thus the scale
of the variables matters.
Since we do not know the scales of our variables, its wise to normalize our data.


```{r}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}

norm_x_train <- x_train_tele
norm_y_train <- y_train_tele
  
norm_x_test <- x_test_tele 
norm_y_test <- y_test_tele 
```

```{r}
norm_x_train$upload <- normalize(norm_x_train$upload)
norm_x_train$webget <- normalize(norm_x_train$webget)
norm_x_train$callwait <- normalize(norm_x_train$callwait)
norm_x_test$upload <- normalize(norm_x_test$upload)
norm_x_test$webget <- normalize(norm_x_test$webget)
norm_x_test$callwait <- normalize(norm_x_test$callwait)
```

```{r}
library(class)
knn_tele <- function(train=x_train_tele,
                     test=x_test_tele,
                     cl=y_train_tele,
                     k=1){
  knn( train = train, test = test, cl = cl, k = k)
}
```

```{r}
knn_accuracy <- mean(knn_tele() == y_test_tele)
knn_accuracy

norm_knn_accuracy <- mean(knn_tele(norm_x_train, norm_x_test, norm_y_train) == norm_y_test)
norm_knn_accuracy
```
```{r cross_validation}
cross_knn_error <- c()
for(i in 1:100){
  cross_knn <- knn.cv(norm_x_train, norm_y_train, k = i, l = 0, prob = FALSE, use.all = TRUE)
  cross_knn_error[i] <- mean(cross_knn != norm_y_train)
}
```

```{r}
plot(cross_knn_error[1:20], xlab = 'k', ylab = 'Error')

```